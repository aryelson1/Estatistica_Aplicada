{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4bd3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad06573e",
   "metadata": {},
   "source": [
    "# 1ª Tarefa\n",
    "\n",
    "Carregue em dataframes os conjuntos de dados referentes ao ano de 2018, 2019 e 2020. Corrija quaisquer erros que apareçam no carregamento dos arquivos. É possível acessar os arquivos\n",
    "compactados diretamente do site, sem precisar baixá-los?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976b1239",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020 = pd.read_csv('https://arquivos.prf.gov.br/arquivos/index.php/s/jdDLrQIf33xXSCe/download', \n",
    "                      compression='zip',encoding='unicode_escape', sep=';')\n",
    "df_2019 = pd.read_csv('https://arquivos.prf.gov.br/arquivos/index.php/s/kRBUylqz6DyQznN/download', \n",
    "                      compression='zip',encoding='unicode_escape', sep=';')\n",
    "df_2018 = pd.read_csv('https://arquivos.prf.gov.br/arquivos/index.php/s/MaC6cieXSFACNWT/download', \n",
    "                      compression='zip',encoding='unicode_escape', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c772890b",
   "metadata": {},
   "source": [
    "Sim, é possível acessar os arquivos compactados. Pois na função read_csv da biblioteca pandas, existe um campo chamado COMPRESSION nele é possível informar que a entrada vai ser um arquivo .ZIP ou outros tipos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b895d9",
   "metadata": {},
   "source": [
    "# 2ª Tarefa\n",
    "\n",
    "Explore os conjuntos de dados, respondendo as questões:\n",
    "\n",
    "#### (a) quantos acidentes ocorreram em cada ano?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc145263",
   "metadata": {},
   "source": [
    "O python tem um função chamada len(), muito utilizanda para retornar o tamanho de uma lista. Ela também serve para os DataFrames pandas, retornando a quantidades de linhas do DataFrame. E como cada acidente é uma linha do DataFrame, só é necessário informar esse total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6f0730",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total acidentes 2020: \",len(df_2020))\n",
    "print(\"Total acidentes 2019: \",len(df_2019))\n",
    "print(\"Total acidentes 2018: \",len(df_2018))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6586a7d5",
   "metadata": {},
   "source": [
    "#### (b) quantas variáveis cada conjunto de dados registra?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43deeee",
   "metadata": {},
   "source": [
    "O python tem um função chamada len(), muito utilizanda para retornar o tamanho de uma lista. Ela também serve para os DataFrames pandas, retornando a quantidades de linhas do DataFrame. Mas podemos fazer uma alteração usando DF.columns para retornar a quantidade de colunas no lugar de linhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cada conjuto de dados registra: \",len(df_2020.columns),\" variáveis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380a80de",
   "metadata": {},
   "source": [
    "#### (c) quais as cinco cidades brasileiras onde mais ocorreram acidentes em rodovias federais?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c37de3",
   "metadata": {},
   "source": [
    "Como a função value_counts retorna uma série contendo contagens de valores únicos. utilizei a coluna municipio para fazer uma filtragem e retornar a quantidade de vezes que cada cidade se repete no DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d90022",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Acidentes 2020 por Cidade\")\n",
    "print(df_2020['municipio'].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1165f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Acidentes 2019 por Cidade\")\n",
    "print(df_2019['municipio'].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f65ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Acidentes 2018 por Cidade\")\n",
    "print(df_2018['municipio'].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26519719",
   "metadata": {},
   "source": [
    "#### (d) quantos acidentes com feridos graves aconteceram na Paraíba em 2019?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c11c927",
   "metadata": {},
   "source": [
    "Primeiro fiz uma filtragem para retornar somente os dados da coluna UF == PB e que tenha pelo menos 1 ferido grave, em seguida utilizei o metodo len(), para somar a quantidade de linhas no DataFrame( já que cada linha corresponde a um acidente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592204e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total de acidentes na paraiba em 2019:\",len(df_2019[ (df_2019['uf'] == \"PB\") & (df_2019['feridos_graves'] > 0)]) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283159a9",
   "metadata": {},
   "source": [
    "# 3ª Tarefa\n",
    "Para cada indicação abaixo, construa um novo dataframe, salvando-o com a terminação .csv.\n",
    "\n",
    "#### (a) ranking de acidentes por estado para todos os anos (um só arquivo combinando a informação dos três anos);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3925c6",
   "metadata": {},
   "source": [
    "Como a função value_counts retorna uma série contendo contagens de valores únicos. utilizei a coluna UF para fazer uma filtragem e retornar a quantidade de vezes que cada uf se repete no DataFrame(já que cada linha é um acidente, a função retorna quantidade de acidentes por UF). Em seguida transfomei o resultado da função value_counts em um novo DataFrame e usei a função fillna() para set o valor do ano referente na coluna 'ano'. Com isso a tabela estava pronta, mas usei rename e index para estilizar o meu DataFrame, e conclui a parte de organização usando o set_index para organizar os dados por 'ano' e 'uf'. Por ultimo transformei o DataFrame em um arquivo .csv, utilizando a função to_csv()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "uf_2020 = df_2020['uf'].value_counts()\n",
    "uf_2020 = pd.DataFrame(data = uf_2020,columns = ['uf','ano']).fillna(2020)\n",
    "uf_2020 = uf_2020.rename(columns={'uf': 'Acidentes'})\n",
    "uf_2020['uf'] = uf_2020.index\n",
    "uf_2020 = uf_2020.set_index(['ano','uf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3934dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "uf_2019 = df_2019['uf'].value_counts()\n",
    "df = pd.DataFrame(data = uf_2019,columns = ['uf','ano']).fillna(2019)\n",
    "df = df.rename(columns={'uf': 'Acidentes'})\n",
    "df['uf'] = df.index\n",
    "uf_2019 = df.set_index(['ano','uf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3cb62d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uf_2018 = df_2018['uf'].value_counts()\n",
    "uf_2018 = pd.DataFrame(data = uf_2018,columns = ['uf','ano']).fillna(2018)\n",
    "uf_2018 = uf_2018.rename(columns={'uf': 'Acidentes'})\n",
    "uf_2018['uf'] = uf_2018.index\n",
    "uf_2018 = uf_2018.set_index(['ano','uf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f9d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_Completo = pd.concat([uf_2020,uf_2019,uf_2018])\n",
    "DF_Completo.to_csv('Tarefa3º_Q(A).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7589383b",
   "metadata": {},
   "source": [
    "#### (b) acidentes por dia da semana para todos os anos (um só arquivo combinando a informação dos três anos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c110a",
   "metadata": {},
   "source": [
    "Como a função value_counts retorna uma série contendo contagens de valores únicos. utilizei a coluna 'dia_semana' para fazer uma filtragem e retornar a quantidade de vezes que cada dia da semana se repete no DataFrame(já que cada linha é um acidente, a função retorna quantidade de acidentes por dia da semana). Em seguida transfomei o resultado da função value_counts em um novo DataFrame e usei a função fillna() para set o valor do ano referente na coluna 'ano'. Com isso a tabela estava pronta, mas usei rename e index para estilizar o meu DataFrame, e conclui a parte de organização usando o set_index para organizar os dados por 'ano' e 'dia_semana'. Por ultimo transformei o DataFrame em um arquivo .csv, utilizando a função to_csv()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc25aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "diaS_2020 = df_2020['dia_semana'].value_counts()\n",
    "diaS_2020 = pd.DataFrame(data = diaS_2020,columns = ['dia_semana','ano']).fillna(2020)\n",
    "diaS_2020 = diaS_2020.rename(columns={'dia_semana': 'Acidentes'})\n",
    "diaS_2020['dia_semana'] = diaS_2020.index\n",
    "diaS_2020 = diaS_2020.set_index(['ano','dia_semana'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04117d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "diaS_2019 = df_2019['dia_semana'].value_counts()\n",
    "diaS_2019  = pd.DataFrame(data = diaS_2019 ,columns = ['dia_semana','ano']).fillna(2019)\n",
    "diaS_2019  = diaS_2019 .rename(columns={'dia_semana': 'Acidentes'})\n",
    "diaS_2019 ['dia_semana'] = diaS_2019 .index\n",
    "diaS_2019 = diaS_2019.set_index(['ano','dia_semana'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097f0a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "diaS_2018 = df_2018['dia_semana'].value_counts()\n",
    "diaS_2018  = pd.DataFrame(data = diaS_2018 ,columns = ['dia_semana','ano']).fillna(2018)\n",
    "diaS_2018  = diaS_2018 .rename(columns={'dia_semana': 'Acidentes'})\n",
    "diaS_2018 ['dia_semana'] = diaS_2018 .index\n",
    "diaS_2018 = diaS_2018.set_index(['ano','dia_semana'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_Completo_dias = pd.concat([diaS_2020,diaS_2019,diaS_2018])\n",
    "DF_Completo_dias.to_csv('Tarefa3º_Q(B).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ac48b",
   "metadata": {},
   "source": [
    "# 4ª Tarefa\n",
    "\n",
    "Com relação a ocorrência dos acidentes, responda:\n",
    "\n",
    "#### (a) qual a causa mais frequente e a mais rara de acidentes registrados nos três anos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab51bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo = pd.concat([df_2020,df_2019,df_2018])\n",
    "causas_acidentes = df_completo['causa_acidente'].value_counts()\n",
    "causas_acidentes = pd.DataFrame(causas_acidentes,columns=[\"causa_acidente\"])\n",
    "causas_acidentes = causas_acidentes.rename(columns={'causa_acidente': 'Quantidade de Acidentes'})\n",
    "causas_acidentes['causa_acidente'] = causas_acidentes.index\n",
    "causas_acidentes = causas_acidentes.set_index(['causa_acidente'])\n",
    "causas_acidentes.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb753d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "causas_acidentes.tail(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd627b8",
   "metadata": {},
   "source": [
    "#### (b) qual a proporção de pessoas ilesas e de feridos graves por mês em cada um dos anos considerados? (proporção = numero de ilesos ou feridos graves/ número total de pessoas envolvidas no acidente);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c42be3",
   "metadata": {},
   "source": [
    "Primeiro usei a função loc para dividir o dataFrame com os dados que necessitava usar, depois utilizei a função apply com lambda para transformar a coluna data_inversa em Mes, fiz a proporção de cada mes utilizando um For para criar uma lista com todas as proporções seperada por mes. Com isso os dados já estavam prontos, só era necessario estilizar e juntar todos e um unico dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e584ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mes = df_2018.loc[:,[\"data_inversa\",\"feridos_graves\",\"ilesos\",\"ignorados\",\"feridos\"]]\n",
    "df_mes['data_inversa'] = df_mes['data_inversa'].apply(lambda x: str(x)[5:7])\n",
    "somaIlesos = []\n",
    "somaGraves = []\n",
    "for i in range(1,13):\n",
    "    if i < 10:\n",
    "        m1 = df_mes[df_mes['data_inversa'] == '0'+str(i)]\n",
    "    else:\n",
    "        m1 = df_mes[df_mes['data_inversa'] == str(i)]\n",
    "    somaIlesos.append((m1['ilesos'].sum()) / (m1['feridos_graves'].sum()+m1['ignorados'].sum()+m1['feridos'].sum()+m1['ilesos'].sum()))\n",
    "    somaGraves.append((m1['feridos_graves'].sum()) / (m1['feridos_graves'].sum()+m1['ignorados'].sum()+m1['feridos'].sum()+m1['ilesos'].sum()))\n",
    "df__2018 = pd.DataFrame(list(zip(somaIlesos,somaGraves)),columns=[\"Proporção Ilesos\",'Proporção Feridos Graves'])\n",
    "meses = pd.DataFrame(np.arange(1,13),columns=['Meses'])\n",
    "df__2018 = pd.concat([df__2018,meses], axis = 1)\n",
    "df__2018 = df__2018.assign(Ano=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b3336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mes = df_2019.loc[:,[\"data_inversa\",\"feridos_graves\",\"ilesos\",\"ignorados\",\"feridos\"]]\n",
    "df_mes['data_inversa'] = df_mes['data_inversa'].apply(lambda x: str(x)[5:7])\n",
    "somaIlesos = []\n",
    "somaGraves = []\n",
    "for i in range(1,13):\n",
    "    if i < 10:\n",
    "        m1 = df_mes[df_mes['data_inversa'] == '0'+str(i)]\n",
    "    else:\n",
    "        m1 = df_mes[df_mes['data_inversa'] == str(i)]\n",
    "    somaIlesos.append((m1['ilesos'].sum()) / (m1['feridos_graves'].sum()+m1['ignorados'].sum()+m1['feridos'].sum()+m1['ilesos'].sum()))\n",
    "    somaGraves.append((m1['feridos_graves'].sum()) / (m1['feridos_graves'].sum()+m1['ignorados'].sum()+m1['feridos'].sum()+m1['ilesos'].sum()))\n",
    "\n",
    "df__2019 = pd.DataFrame(list(zip(somaIlesos,somaGraves)),columns=[\"Proporção Ilesos\",'Proporção Feridos Graves'])\n",
    "meses = pd.DataFrame(np.arange(1,13),columns=['Meses'])\n",
    "df__2019 = pd.concat([df__2019,meses], axis = 1)\n",
    "df__2019 = df__2019.assign(Ano=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f96f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mes = df_2020.loc[:,[\"data_inversa\",\"feridos_graves\",\"ilesos\",\"ignorados\",\"feridos\"]]\n",
    "df_mes['data_inversa'] = df_mes['data_inversa'].apply(lambda x: str(x)[5:7])\n",
    "somaIlesos = []\n",
    "somaGraves = []\n",
    "for i in range(1,13):\n",
    "    if i < 10:\n",
    "        m1 = df_mes[df_mes['data_inversa'] == '0'+str(i)]\n",
    "    else:\n",
    "        m1 = df_mes[df_mes['data_inversa'] == str(i)]\n",
    "    somaIlesos.append((m1['ilesos'].sum()) / (m1['feridos_graves'].sum()+m1['ignorados'].sum()+m1['feridos'].sum()+m1['ilesos'].sum()))\n",
    "    somaGraves.append((m1['feridos_graves'].sum()) / (m1['feridos_graves'].sum()+m1['ignorados'].sum()+m1['feridos'].sum()+m1['ilesos'].sum()))\n",
    "\n",
    "df__2020 = pd.DataFrame(list(zip(somaIlesos,somaGraves)),columns=[\"Proporção Ilesos\",'Proporção Feridos Graves'])\n",
    "meses = pd.DataFrame(np.arange(1,13),columns=['Meses'])\n",
    "df__2020 = pd.concat([df__2020,meses], axis = 1)\n",
    "df__2020 = df__2020.assign(Ano=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df__2020,df__2019,df__2018]).set_index(['Ano','Meses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfa1fd3",
   "metadata": {},
   "source": [
    "#### (c) mostre, reorganizando o conjunto de dados, se a pandemia conseguiu diminuir ou não\n",
    "a incidência de acidentes nas rodovias federais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a246a524",
   "metadata": {},
   "source": [
    "Usando filtragem basica, separei os meses de março(inicio da pandemia) até dezembro de todos os anos estudados, logo após somei \n",
    "o total de acidentes utilizando a função len() do python, e imprimi total de acidentes durante os meses de pandemia e comparei com os anos sem pandemia e a diferença de acidentes entre os anos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992aea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CP_2020 = df_2020[ (df_2020['data_inversa'] >=  '2020-03-01')]\n",
    "SP_2019 = df_2019[ (df_2019['data_inversa'] >=  '2019-03-01')]\n",
    "SP_2018 = df_2018[ (df_2018['data_inversa'] >=  '2018-03-01')]\n",
    "print(\"Comparação de total de acidentes, durante pandemia de 2020 e sem pandemia em 2018 e 2019\")\n",
    "print(\"Total acidentes 2020: \",len(CP_2020))\n",
    "print(\"Total acidentes 2019: \",len(SP_2019))\n",
    "print(\"Total acidentes 2018: \",len(SP_2018))\n",
    "\n",
    "print(\"Diferença de acidentes de 2020 para 2019:\", len(CP_2020) - len(SP_2019),\"Acidentes\")\n",
    "print(\"Diferença de acidentes de 2020 para 2018:\", len(CP_2020) - len(SP_2018),\"Acidentes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
